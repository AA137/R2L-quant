## R2L<br><sub>Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis</sub>

This repository is for the new Neral Light Field (NeLF) method introduced in the following paper:
> **Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis** [[Arxiv](https://arxiv.org/abs/2203.17261)] [[Project](https://snap-research.github.io/R2L/)] \
> [Huan Wang](http://huanwang.tech/) [1,2], [Jian Ren](https://alanspike.github.io/) [1], [Zeng Huang](https://zeng.science/) [1], [Kyle Olszewski](https://kyleolsz.github.io/) [1], [Menglei Chai](https://mlchai.com/) [1], [Yun Fu](http://www1.ece.neu.edu/~yunfu/) [2], and [Sergey Tulyakov](http://www.stulyakov.com/) [1] \
> [1] Snap Inc., [2] Northeastern University,  \
> Work done when Huan was an intern at Snap Inc.

**[TL;DR]** We present R2L, a deep (88-layer) residual MLP network that can represent the neural *light* field (NeLF) of complex synthetic and real-world scenes. It is featured by compact representation size (~20MB storage size), faster rendering speed (~30x speedup than NeRF), significantly improved visual quality (1.4dB boost than NeRF), with no whistles and bells (no special data structure or parallelism required).

<center><img src="imgs/frontpage.png" width="700" hspace="10"></center>

## 1. How to Run?
Code will be released soon. Stay tuned!


## 2. Results
See our [project webpage](https://snap-research.github.io/R2L/)
